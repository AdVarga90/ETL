{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T02:44:24.507996Z",
     "start_time": "2022-09-24T02:44:24.505438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Goal of this notebook is to help with migrating manual Excel reports to automated Hadoop/Tableau platform\n",
    "# It reads Excel WB and extracts information about fields from pivot tables\n",
    "# 4 main categories of fields - actively used in pivot table, not in usage, calculated field, \"group by' (dimensions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T02:44:24.986011Z",
     "start_time": "2022-09-24T02:44:24.510346Z"
    }
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import multiprocessing\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T02:44:24.990758Z",
     "start_time": "2022-09-24T02:44:24.988037Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl') # slicer extension warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:15:55.608244Z",
     "start_time": "2022-09-24T03:15:55.605120Z"
    }
   },
   "outputs": [],
   "source": [
    "excel_list = os.listdir('excel_pivot_extractor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:15:56.613974Z",
     "start_time": "2022-09-24T03:15:56.610188Z"
    }
   },
   "outputs": [],
   "source": [
    "excel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:16:07.350161Z",
     "start_time": "2022-09-24T03:16:07.346919Z"
    }
   },
   "outputs": [],
   "source": [
    "df_write = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:16:07.359512Z",
     "start_time": "2022-09-24T03:16:07.352438Z"
    }
   },
   "outputs": [],
   "source": [
    "# create empty excel sheet for appending\n",
    "df_write.to_excel('excel_pivot_extractor/extracted_pivot_details.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:16:07.363680Z",
     "start_time": "2022-09-24T03:16:07.361498Z"
    }
   },
   "outputs": [],
   "source": [
    "# wb = openpyxl.load_workbook('excel_pivot_extractor/inb_main_INB 2.0 monitor report 20220617_no_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:16:07.373519Z",
     "start_time": "2022-09-24T03:16:07.365816Z"
    }
   },
   "outputs": [],
   "source": [
    "# open the excel sheet for writing in openpyxl\n",
    "writer = pd.ExcelWriter('excel_pivot_extractor/extracted_pivot_details.xlsx', engine='openpyxl', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:16:07.378333Z",
     "start_time": "2022-09-24T03:16:07.375419Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of all excel workbook in the folder\n",
    "excel_list = [s for s in excel_list if re.search('xlsx', s)]\n",
    "excel_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:16:07.382861Z",
     "start_time": "2022-09-24T03:16:07.380409Z"
    }
   },
   "outputs": [],
   "source": [
    "# four categories of fields I want to gather\n",
    "list_of_fields = ['used_field_list','notu_field_list','calc_field_list','group_field_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T02:44:25.074957Z",
     "start_time": "2022-09-24T02:44:25.065953Z"
    }
   },
   "source": [
    " core function for extracting pivot fields for MULTIPROCESSING\n",
    "def extr_pivots(num_rep):\n",
    "    exc_rep = excel_list[num_rep]\n",
    "    used_field_list = []\n",
    "    notu_field_list = []\n",
    "    calc_field_list = []\n",
    "    group_field_list = []\n",
    "    # print the file to be read\n",
    "    print(\"Loading \"+exc_rep+\" started at \" + str(datetime.datetime.now().strftime(\"%B %-d %Y %H:%M:%S\")))\n",
    "    \n",
    "    # the performance bottleneck is loading the workbooks especially with data sheets\n",
    "    # not to mention that openpyxl doesn't like formatted (coloured) pivot tables\n",
    "    wb = openpyxl.load_workbook('excel_pivot_extractor/'+exc_rep)\n",
    "    sheets_len = len(wb._sheets)\n",
    "    pivots_len = 0\n",
    "    for sh in range(0,len(wb._sheets)):\n",
    "        pivots_len = pivots_len + len(wb._sheets[sh]._pivots)\n",
    "    \n",
    "    # print the file, execution time and details of how many pivots and sheets were processed\n",
    "    print(exc_rep + \" has succesfully loaded and contains \"+str(sheets_len)+\" sheets and \"+str(pivots_len)+\" pivots. Finished at \" + str(datetime.datetime.now().strftime(\"%B %-d %Y %H:%M:%S\")))\n",
    "    \n",
    "    # sheets in WB\n",
    "    for sh in range(0,len(wb._sheets)):\n",
    "        # pivots in a sheet\n",
    "        for pi in range(0,len(wb._sheets[sh]._pivots)):\n",
    "            # fields in a pivot\n",
    "            for ca in range(0,len(wb._sheets[sh]._pivots[pi].cache.cacheFields)):\n",
    "                # if a property \"sharedItems\" of the field is existing then it is available in the pivot table  \n",
    "                try: \n",
    "                    if wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].sharedItems.count > 0:\n",
    "                        used_field_list.append(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name)\n",
    "                    else:\n",
    "                        notu_field_list.append(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name)\n",
    "                except:\n",
    "                    # formula for calculated fields\n",
    "                    try: \n",
    "                        if len(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].formula) > 0:\n",
    "                            calc_field_list.append(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name)\n",
    "                    except: \n",
    "                        # field group for group by dimension\n",
    "                        try:\n",
    "                            if type(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].fieldGroup) == openpyxl.pivot.cache.FieldGroup:\n",
    "                                group_field_list.append(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name)\n",
    "                        except:\n",
    "                            print(\"Didnt assign \"+ (wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name))\n",
    "\n",
    "    # deduplicating output for each workbook\n",
    "    used_field_list = pd.DataFrame(np.unique(used_field_list))\n",
    "    notu_field_list = pd.DataFrame(np.unique(notu_field_list))\n",
    "    calc_field_list = pd.DataFrame(np.unique(calc_field_list))\n",
    "    group_field_list = pd.DataFrame(np.unique(group_field_list))\n",
    "\n",
    "    # output part\n",
    "    out_dic = {}\n",
    "    out_dic['Name'] = exc_rep[:6]\n",
    "    #write each DataFrame to a specific sheet\n",
    "    for i, ff in enumerate(list_of_fields):\n",
    "            out_dic[ff] = eval(ff)\n",
    "    return out_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T02:44:25.080357Z",
     "start_time": "2022-09-24T02:44:25.077020Z"
    }
   },
   "source": [
    " This function allowed me to write into excel WB simultaneously however each time an instance of the multiprocess finishes it saves the workbook and overwrites the previous instance\n",
    "def mp_handler():\n",
    "    pool_obj = multiprocessing.Pool()\n",
    "    \n",
    "    # imap_unordered() function iterates items in the iterable one at a time and issue a task in the process pool. \n",
    "    # That calls the specified function on the iterable. Then returns an iterable of return values. \n",
    "    # The return values are yielded in the order that tasks are completed, not the order that the tasks were issued to the process pool.\n",
    "    for i, result in enumerate(pool_obj.imap_unordered(extr_pivots, range(0,len(excel_list))),1):\n",
    "        \n",
    "        # the four categories of fields\n",
    "        for c, ff in enumerate(list_of_fields):\n",
    "            result[ff].to_excel(writer, sheet_name=(result['Name']), index=False, startcol = c)\n",
    "        # progress bar formatted as stderr instead of stdout to distinguish the progress in the output\n",
    "        sys.stderr.write('\\rdone {0:%}'.format(i/len(excel_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T02:57:23.128810Z",
     "start_time": "2022-09-24T02:44:25.082405Z"
    }
   },
   "source": [
    "if __name__=='__main__':\n",
    "    mp_handler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:16:13.883402Z",
     "start_time": "2022-09-24T03:16:13.880324Z"
    }
   },
   "outputs": [],
   "source": [
    "# definition of 4 category lists outside of the loop\n",
    "used_field_list_tot = []\n",
    "notu_field_list_tot = []\n",
    "calc_field_list_tot = []\n",
    "group_field_list_tot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:16:39.070364Z",
     "start_time": "2022-09-24T03:16:13.889218Z"
    }
   },
   "outputs": [],
   "source": [
    "# main part to extract pivot fields from the workbooks \n",
    "for exc_rep in tqdm(excel_list):\n",
    "    #for exc_rep in excel_list:\n",
    "    used_field_list = []\n",
    "    notu_field_list = []\n",
    "    calc_field_list = []\n",
    "    group_field_list = []\n",
    "    \n",
    "    # print the file to be read\n",
    "    print(\"Loading \"+exc_rep+\" WB - started at \" + str(datetime.datetime.now().strftime(\"%B %-d %Y %H:%M:%S\")))\n",
    "    \n",
    "    # the performance bottleneck is loading the workbooks especially with data sheets\n",
    "    # not to mention that openpyxl doesn't like formatted (coloured) pivot tables\n",
    "    wb = openpyxl.load_workbook('excel_pivot_extractor/'+exc_rep)\n",
    "    sheets_len = len(wb._sheets)\n",
    "    pivots_len = 0\n",
    "    for sh in range(0,len(wb._sheets)):\n",
    "        pivots_len = pivots_len + len(wb._sheets[sh]._pivots)\n",
    "    \n",
    "    # print the file, execution time and details of how many pivots and sheets were processed\n",
    "    print(\"WB has succesfully loaded and contains \"+str(sheets_len)+\" sheets and \"+str(pivots_len)+\" pivots. Finished at \" + str(datetime.datetime.now().strftime(\"%B %-d %Y %H:%M:%S\")))\n",
    "    \n",
    "    # sheets in WB\n",
    "    for sh in range(0,len(wb._sheets)):\n",
    "        # pivots in a sheet\n",
    "        for pi in range(0,len(wb._sheets[sh]._pivots)):\n",
    "            # fields in a pivot\n",
    "            for ca in range(0,len(wb._sheets[sh]._pivots[pi].cache.cacheFields)):\n",
    "                # if a property \"sharedItems\" of the field is existing then it is available in the pivot table  \n",
    "                try: \n",
    "                    if wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].sharedItems.count > 0:\n",
    "                        used_field_list.append(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name)\n",
    "                    else:\n",
    "                        notu_field_list.append(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name)\n",
    "                except:\n",
    "                    # formula stands for calculated fields\n",
    "                    try: \n",
    "                        if len(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].formula) > 0:\n",
    "                            calc_field_list.append(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name)\n",
    "                    except: \n",
    "                        # field group for group by dimension\n",
    "                        try:\n",
    "                            if type(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].fieldGroup) == openpyxl.pivot.cache.FieldGroup:\n",
    "                                group_field_list.append(wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name)\n",
    "                        except:\n",
    "                            print(\"Didnt assign \"+ (wb._sheets[sh]._pivots[pi].cache.cacheFields[ca].name))\n",
    "\n",
    "    # deduplicating output for each workbook\n",
    "    used_field_list = pd.DataFrame(np.unique(used_field_list))\n",
    "    notu_field_list = pd.DataFrame(np.unique(notu_field_list))\n",
    "    calc_field_list = pd.DataFrame(np.unique(calc_field_list))\n",
    "    group_field_list = pd.DataFrame(np.unique(group_field_list))\n",
    "\n",
    "    used_field_list_tot.append(used_field_list)\n",
    "    notu_field_list_tot.append(notu_field_list)\n",
    "    calc_field_list_tot.append(calc_field_list)\n",
    "    group_field_list_tot.append(group_field_list)\n",
    "    \n",
    "    #write each DataFrame to a specific sheet\n",
    "    for i, ff in enumerate(list_of_fields):\n",
    "            eval(ff).to_excel(writer, sheet_name=(exc_rep[:6]), index=False, startcol = i)\n",
    "\n",
    "    #close the Pandas Excel writer and output the Excel file\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:27:20.066800Z",
     "start_time": "2022-09-24T03:27:20.064293Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each category count appearances and prepare summary, TBD - as a loop of each category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:27:22.319625Z",
     "start_time": "2022-09-24T03:27:22.299535Z"
    }
   },
   "outputs": [],
   "source": [
    "flat_list_used_field = pd.DataFrame()\n",
    "for x in used_field_list_tot:\n",
    "    try: \n",
    "        x[0] = x[0].str.lower()\n",
    "        flat_list_used_field = flat_list_used_field.append(x,ignore_index=True)\n",
    "    except: print(x)\n",
    "\n",
    "flat_list_used_field = flat_list_used_field.value_counts()\n",
    "flat_list_used_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:27:27.079902Z",
     "start_time": "2022-09-24T03:27:27.061097Z"
    }
   },
   "outputs": [],
   "source": [
    "flat_list_notu_used_field = pd.DataFrame()\n",
    "for x in notu_field_list_tot:\n",
    "    try: \n",
    "        x[0] = x[0].str.lower()\n",
    "        flat_list_notu_used_field = flat_list_notu_used_field.append(x,ignore_index=True)\n",
    "    except: print(x)\n",
    "flat_list_notu_used_field = flat_list_notu_used_field.value_counts()\n",
    "flat_list_notu_used_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:27:28.063379Z",
     "start_time": "2022-09-24T03:27:28.044822Z"
    }
   },
   "outputs": [],
   "source": [
    "flat_list_calc_field = pd.DataFrame()\n",
    "for x in calc_field_list_tot:\n",
    "    try: \n",
    "        x[0] = x[0].str.lower()\n",
    "        flat_list_calc_field = flat_list_calc_field.append(x,ignore_index=True)\n",
    "    except: print(x)\n",
    "flat_list_calc_field = flat_list_calc_field.value_counts()\n",
    "flat_list_calc_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:27:29.238939Z",
     "start_time": "2022-09-24T03:27:29.223975Z"
    }
   },
   "outputs": [],
   "source": [
    "flat_list_group_field = pd.DataFrame()\n",
    "for x in group_field_list_tot:\n",
    "    try: \n",
    "        x[0] = x[0].str.lower()\n",
    "        flat_list_group_field = flat_list_group_field.append(x,ignore_index=True)\n",
    "    except: print(x)\n",
    "\n",
    "flat_list_group_field = flat_list_group_field.value_counts()\n",
    "flat_list_group_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:28:56.712047Z",
     "start_time": "2022-09-24T03:28:56.700624Z"
    }
   },
   "outputs": [],
   "source": [
    "# finalize the summary\n",
    "summary_tot = pd.concat([flat_list_used_field,flat_list_notu_used_field,flat_list_calc_field,flat_list_group_field],axis=1)\n",
    "summary_tot.rename(columns = {0:'used_fields', 1:'not_used_fields', 2:'calculated_fields', 3:'groupby_fields'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T03:29:11.838142Z",
     "start_time": "2022-09-24T03:29:11.727663Z"
    }
   },
   "outputs": [],
   "source": [
    "# write it to the excel sheet\n",
    "summary_tot.to_excel(writer, sheet_name=('Total'), index=True)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
